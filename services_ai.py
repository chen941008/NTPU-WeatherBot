# services_ai.py
import os
import json
import logging
import requests
import torch
import random
from typing import Dict, Any, List, Union
import google.generativeai as genai
from google.api_core import exceptions
from sentence_transformers import util

# å¼•ç”¨å°ˆæ¡ˆå…§æ¨¡çµ„
from extensions import embedding_model, cc, db
from models import User

# å¾ config å¼•å…¥å¿…è¦çš„è®Šæ•¸
from config import (
    INTENT_KNOWLEDGE_BASE, 
    CITY_ALIASES, 
    RECIPES_URL, 
    GOOGLE_API_KEY, 
    MODEL_PRIORITY
)

logger = logging.getLogger(__name__)

# å…¨åŸŸè®Šæ•¸
CACHED_RECIPES = []
RECIPE_EMBEDDINGS = None
corpus_embeddings = None
corpus_sentences = []
intent_map = []

# åˆå§‹åŒ– Gemini
if GOOGLE_API_KEY:
    genai.configure(api_key=GOOGLE_API_KEY)

# ==========================================
# 1. æ ¸å¿ƒ AI å‘¼å«å‡½å¼ (åŸæœ¬ç¼ºå°‘çš„!)
# ==========================================
def generate_content_safe(prompt_parts: Union[str, List[Any]]) -> Any:
    """
    ä¾åºå˜—è©¦ MODEL_PRIORITY ä¸­çš„æ¨¡å‹ä¾†ç”Ÿæˆå…§å®¹ã€‚
    """
    if not GOOGLE_API_KEY:
        raise Exception("API Key æœªè¨­å®š")

    last_error = None

    for model_name in MODEL_PRIORITY:
        try:
            current_model = genai.GenerativeModel(model_name)
            response = current_model.generate_content(prompt_parts)
            return response

        except exceptions.ResourceExhausted:
            logger.warning(f"æ¨¡å‹ {model_name} é¡åº¦å·²æ»¿ï¼Œåˆ‡æ›ä¸‹ä¸€å€‹...")
            continue
        except exceptions.ServiceUnavailable:
            logger.warning(f"æ¨¡å‹ {model_name} æš«æ™‚ç„¡æ³•é€£ç·šï¼Œåˆ‡æ›ä¸‹ä¸€å€‹...")
            continue
        except (exceptions.NotFound, exceptions.InvalidArgument) as e:
            logger.warning(f"æ¨¡å‹ {model_name} ä¸å­˜åœ¨æˆ–ç„¡æ•ˆï¼Œè·³éã€‚")
            continue
        except Exception as e:
            logger.error(f"æ¨¡å‹ {model_name} ç™¼ç”ŸéŒ¯èª¤: {e}")
            last_error = str(e)
            continue 

    raise Exception(f"æ‰€æœ‰æ¨¡å‹éƒ½å˜—è©¦å¤±æ•—ã€‚æœ€å¾ŒéŒ¯èª¤: {last_error}")

# ==========================================
# 2. å•Ÿå‹•èˆ‡è¼‰å…¥é‚è¼¯
# ==========================================
def startup_load_recipes():
    """
    å•Ÿå‹•è¼‰å…¥ï¼šè®€å– -> è½‰ç¹é«” -> å»ºç«‹å…©éšæ®µå‘é‡ç´¢å¼•
    """
    global CACHED_RECIPES, RECIPE_EMBEDDINGS, corpus_embeddings, corpus_sentences, intent_map
    
    recipe_json_path = "recipes.json"
    data = []
    cleaned = []

    # 1. å˜—è©¦è®€å–æœ¬åœ°
    if os.path.exists(recipe_json_path):
        print(f"ğŸ“‚ ç™¼ç¾æœ¬åœ°é£Ÿè­œæª”æ¡ˆï¼Œæ­£åœ¨è®€å–...", flush=True)
        try:
            with open(recipe_json_path, "r", encoding="utf-8") as f:
                data = json.load(f)
        except Exception as e:
            print(f"âŒ æœ¬åœ°è®€å–å¤±æ•—: {e}ï¼Œå°‡å˜—è©¦ç¶²è·¯ä¸‹è¼‰ã€‚", flush=True)
    
    # 2. å¦‚æœæœ¬åœ°æ²’æœ‰ï¼Œå¼·åˆ¶ä¸‹è¼‰
    if not data:
        print(f"ğŸŒ æ­£åœ¨å¾ç¶²è·¯ä¸‹è¼‰é£Ÿè­œè³‡æ–™åº«...", flush=True)
        try:
            response = requests.get(RECIPES_URL, timeout=60)
            if response.status_code == 200:
                data = response.json()
                with open(recipe_json_path, "w", encoding="utf-8") as f:
                    json.dump(data, f, ensure_ascii=False)
            else:
                print(f"âŒ ä¸‹è¼‰å¤±æ•— (Status: {response.status_code})", flush=True)
        except Exception as e:
            print(f"âŒ ä¸‹è¼‰éŒ¯èª¤: {e}", flush=True)

    # 3. åŸ·è¡Œç°¡è½‰ç¹èˆ‡æ¸…æ´—
    if data:
        for dish in data:
            new_dish = dish.copy()
            if "name" in new_dish:
                new_dish["name"] = cc.convert(new_dish["name"])
            if "description" in new_dish:
                new_dish["description"] = cc.convert(new_dish["description"])
            if "ingredients" in new_dish:
                new_dish["ingredients"] = cc.convert(str(new_dish["ingredients"]))
            cleaned.append(new_dish)
        
        CACHED_RECIPES = cleaned
        print(f"âœ… é£Ÿè­œè¼‰å…¥ä¸¦ç¹é«”åŒ–å®Œæˆï¼å…± {len(CACHED_RECIPES)} é“ã€‚", flush=True)
        
        # 4. å»ºç«‹é£Ÿè­œåç¨±å‘é‡ç´¢å¼•
        if CACHED_RECIPES:
            print("ğŸ³ æ­£åœ¨ç‚ºé£Ÿè­œåç¨±å»ºç«‹å°ˆå±¬å‘é‡ç´¢å¼•...", flush=True)
            try:
                recipe_names = [r['name'] for r in CACHED_RECIPES]
                RECIPE_EMBEDDINGS = embedding_model.encode(recipe_names, convert_to_tensor=True)
                print(f"âœ… é£Ÿè­œå‘é‡ç´¢å¼•å»ºç«‹å®Œæˆï¼", flush=True)

                # å‹•æ…‹æ³¨å…¥æ„åœ–
                if "search_recipe" in INTENT_KNOWLEDGE_BASE:
                    INTENT_KNOWLEDGE_BASE["search_recipe"].extend(recipe_names)
                    print(f"ğŸ’‰ å·²æ³¨å…¥ {len(recipe_names)} å€‹èœååˆ°æ„åœ–ç³»çµ±ã€‚", flush=True)
            except Exception as e:
                print(f"âŒ å»ºç«‹å‘é‡ç´¢å¼•æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", flush=True)

    # 5. å»ºç«‹æ„åœ–å‘é‡ç´¢å¼• (Knowledge Base)
    print("ğŸ§  æ­£åœ¨å°‡æ„åœ–è³‡æ–™åº«è½‰ç‚ºå‘é‡...", flush=True)
    corpus_sentences = []
    intent_map = [] 

    for intent, examples in INTENT_KNOWLEDGE_BASE.items():
        for example in examples:
            corpus_sentences.append(example)
            intent_map.append(intent)

    corpus_embeddings = embedding_model.encode(corpus_sentences, convert_to_tensor=True)
    print("âœ… BGE-M3 æ„åœ–ç´¢å¼•å»ºç«‹å®Œæˆï¼", flush=True)

def ensure_recipes_loaded():
    if not CACHED_RECIPES:
        startup_load_recipes()

# ==========================================
# 3. æ„åœ–åˆ†æèˆ‡æœå°‹é‚è¼¯
# ==========================================
def analyze_intent(user_text: str) -> Dict[str, Any]:
    global corpus_embeddings
    if corpus_embeddings is None:
        startup_load_recipes()

    query_embedding = embedding_model.encode(user_text, convert_to_tensor=True)
    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]
    best_score = torch.max(cos_scores)
    best_idx = torch.argmax(cos_scores).item()
    predicted_intent = intent_map[best_idx]
    
    logger.info(f"è¼¸å…¥: '{user_text}' | æ„åœ–: {predicted_intent} | åˆ†æ•¸: {best_score:.4f}")
    
    if best_score < 0.65:
        return {"intent": "chat"}

    result = {"intent": predicted_intent}

    # åƒæ•¸èƒå–é‚è¼¯
    if predicted_intent in ["weather", "clothing_advice", "search_nearby"]:
        found_city = None
        for alias, real_name in CITY_ALIASES.items():
            if alias in user_text:
                found_city = real_name
                break
        result["location"] = found_city

    elif predicted_intent == "search_recipe":
        result["keyword"] = user_text 

    elif predicted_intent == "suggest_by_ingredients":
        stop_words = ["å†°ç®±", "åªå‰©", "å‰©ä¸‹", "åªæœ‰", "æˆ‘æœ‰", "å¯ä»¥åšä»€éº¼", "æ–™ç†", "æ¨è–¦", "é£Ÿæ"]
        clean_text = user_text
        for word in stop_words:
            clean_text = clean_text.replace(word, "")
        result["ingredients"] = clean_text.strip()

    elif predicted_intent == "substitute_ingredient":
        stop_words = ["æ²’æœ‰", "ç¼º", "å°‘äº†", "å¯ä»¥ç”¨", "ä»€éº¼", "ä»£æ›¿", "æ›¿ä»£", "æ›æˆ", "æ€éº¼è¾¦"]
        clean_text = user_text
        for word in stop_words:
            clean_text = clean_text.replace(word, "")
        result["target"] = clean_text.strip()

    return result

def search_recipe_by_ai(user_text: str) -> str:
    global CACHED_RECIPES, RECIPE_EMBEDDINGS
    
    ensure_recipes_loaded()
    if not CACHED_RECIPES or RECIPE_EMBEDDINGS is None:
        return "é£Ÿè­œè³‡æ–™åº«å°šæœªå»ºç«‹ç´¢å¼•ã€‚"

    query_embedding = embedding_model.encode(user_text, convert_to_tensor=True)
    cos_scores = util.cos_sim(query_embedding, RECIPE_EMBEDDINGS)[0]
    best_score = torch.max(cos_scores)
    best_idx = torch.argmax(cos_scores).item()
    
    target_dish = CACHED_RECIPES[best_idx]
    dish_name = target_dish['name']
    
    logger.info(f"é£Ÿè­œæœå°‹: '{user_text}' -> '{dish_name}' ({best_score:.4f})")
    
    if best_score < 0.65:
        return f"æŠ±æ­‰ï¼Œæˆ‘æ‰¾ä¸åˆ°è·Ÿã€Œ{user_text}ã€ç›¸é—œçš„é£Ÿè­œã€‚"

    dish_data_str = json.dumps(target_dish, ensure_ascii=False)
    prompt = f"ä½ æ˜¯å°ˆæ¥­å¤§å»šã€‚è«‹å°‡æ­¤é£Ÿè­œè³‡æ–™ï¼š{dish_data_str}ï¼Œæ•´ç†æˆç¹é«”ä¸­æ–‡æ•™å­¸ã€‚åŒ…å«ä»‹ç´¹ã€é£Ÿæã€æ­¥é©Ÿã€å°æ’‡æ­¥ã€‚"
    
    try:
        response = generate_content_safe(prompt)
        return response.text
    except Exception as e:
        logger.error(f"ç”Ÿæˆå¤±æ•—: {e}")
        return "AI ç”Ÿæˆé£Ÿè­œæ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚"

# ==========================================
# 4. å…¶ä»– AI æœå‹™ (è£œé½ŠåŸæœ¬ app.py éºå¤±çš„åŠŸèƒ½)
# ==========================================

def get_clothing_advice(user_id: str, location: str) -> str:
    """
    å®¢è£½åŒ–ç©¿æ­å»ºè­°
    """
    # é¿å…å¾ªç’°å¼•ç”¨ï¼Œåœ¨å‡½å¼å…§å¼•ç”¨ services_basic
    from services_basic import get_weather_36h, get_user_preference
    
    weather_data = get_weather_36h(location)
    if "error" in weather_data:
        return f"æŠ±æ­‰ï¼Œæˆ‘æ‹¿ä¸åˆ°ã€Œ{location}ã€çš„å¤©æ°£è³‡è¨Šã€‚"
    
    user_prefs = get_user_preference(user_id)
    prompt = f"ä½ æ˜¯ç®¡å®¶ã€‚å¤©æ°£ï¼š{weather_data['full_text']}ã€‚åå¥½ï¼š{user_prefs}ã€‚è«‹çµ¦ç©¿æ­å»ºè­°ã€‚"
    try:
        return generate_content_safe(prompt).text
    except:
        return "AI æš«æ™‚ç„¡æ³•å›æ‡‰ã€‚"

def get_random_recipe() -> str:
    """
    éš¨æ©Ÿé£Ÿè­œ
    """
    ensure_recipes_loaded()
    if not CACHED_RECIPES: return "è³‡æ–™åº«æœªè¼‰å…¥ã€‚"
    dish = random.choice(CACHED_RECIPES)
    return f"ğŸ³ æ¨è–¦ï¼š{dish['name']}\n{dish.get('description','')[:50]}...\n(æƒ³å­¸åšé€™é“èœå—ï¼Ÿè«‹è¼¸å…¥ã€Œé£Ÿè­œ {dish['name']}ã€)"

def suggest_recipe_by_ingredients(user_id: str, ingredients: str) -> str:
    """
    å†°ç®±é£Ÿææ¨è–¦
    """
    ensure_recipes_loaded()
    # å–å‰ 30 é“èœç•¶ä½œåƒè€ƒæ¨£æœ¬çµ¦ AI
    sample_recipes = "\n".join([r['name'] for r in CACHED_RECIPES[:30]])
    prompt = f"""
    ä½ æ˜¯è°æ˜ä¸»å»šã€‚ä½¿ç”¨è€…æœ‰é£Ÿæï¼šã€{ingredients}ã€‘ã€‚
    
    è«‹æ¨è–¦ 1~2 é“é©åˆçš„æ–™ç†ï¼Œä¸¦èªªæ˜ç†ç”±ã€‚
    å¦‚æœè³‡æ–™åº«è£¡çš„èœ ({sample_recipes}...) é©åˆï¼Œå„ªå…ˆæ¨è–¦ï¼Œä¸¦å¼•å°ä½¿ç”¨è€…æŸ¥è©¢ã€‚
    å¦‚æœä¸é©åˆï¼Œè«‹ç™¼æ®å‰µæ„æ¨è–¦ç°¡å–®æ–™ç†ã€‚
    """
    try:
        return generate_content_safe(prompt).text
    except:
        return "AI æ€è€ƒé£Ÿæä¸­..."

def get_fortune(user_id: str, mood: str) -> str:
    """
    é‹å‹¢åˆ†æ
    """
    # éœ€è¦å¤©æ°£è³‡è¨Šä¾†å¢åŠ é‹å‹¢çš„è±å¯Œåº¦
    from services_basic import get_user_home_city, get_weather_36h
    
    city = get_user_home_city(user_id)
    w_data = get_weather_36h(city)
    w_info = w_data.get("full_text", "å¤©æ°£æœªçŸ¥")

    prompt = f"""
    ä½ æ˜¯è²¼å¿ƒç”Ÿæ´»æ°£è±¡å° AIã€‚
    ä»Šæ—¥å¤©æ°£ï¼š{w_info}ã€‚
    ä½¿ç”¨è€…å¿ƒæƒ…ï¼š{mood}ã€‚
    
    è«‹ç”Ÿæˆä¸€ä»½é‹å‹¢å ±å‘Š (ç¹é«”ä¸­æ–‡)ï¼ŒåŒ…å«ï¼š
    1. ä»Šæ—¥æƒ…ç·’å¤©æ°£
    2. ç¾é£Ÿå‰ç±¤
    3. ç©¿æ­æé†’
    4. å¹¸é‹å°ç‰©
    """
    try:
        return generate_content_safe(prompt).text
    except:
        return "é‹å‹¢ç”Ÿæˆå™¨é€£ç·šä¸­..."

def get_substitute_suggestion(target: str) -> str:
    """
    é£Ÿææ›¿ä»£å»ºè­°
    """
    prompt = f"ä½¿ç”¨è€…æƒ³çŸ¥é“ã€{target}ã€‘çš„æ›¿ä»£å“ã€‚è«‹åˆ—å‡º 3 å€‹æœ€ä½³æ›¿ä»£æ–¹æ¡ˆï¼Œä¸¦èªªæ˜æ¯”ä¾‹èˆ‡å£æ„Ÿå·®ç•°ã€‚"
    try:
        return generate_content_safe(prompt).text
    except:
        return "AI æŸ¥è©¢æ›¿ä»£é£Ÿæä¸­..."

def generate_tour_guide_text(places_str: str) -> str:
    """
    [æ–°å¢] ç”Ÿæˆå°éŠä»‹ç´¹æ–‡æ¡ˆ (é…åˆ services_basic çš„ get_nearby_places)
    """
    prompt = f"""
    ä½¿ç”¨è€…é™„è¿‘æœ‰ä»¥ä¸‹æ™¯é»ï¼š
    {places_str}

    è«‹æ‰®æ¼”ä¸€ä½ã€Œç†±æƒ…æ´»æ½‘çš„åœ¨åœ°å°éŠã€ï¼š
    1. æŒ‘é¸ 3 å€‹å€¼å¾—å»çš„åœ°æ–¹ã€‚
    2. ç”¨ç”Ÿå‹•èªè¨€ä»‹ç´¹ã€‚
    3. åŠ ä¸Š Emojiã€‚
    """
    try:
        return generate_content_safe(prompt).text
    except:
        return "é™„è¿‘æœ‰ä¸å°‘å¥½ç©çš„æ™¯é»å–”ï¼(AI å°éŠæš«æ™‚ä¼‘æ¯ä¸­)"